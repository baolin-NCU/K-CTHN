import tensorflow as tf
from tensorflow.keras import layers
import os, time, datetime
os.environ["KERAS_BACKEND"] = "tensorflow"
os.environ["THEANO_FLAGS"] = "device=cuda,floatX=float32"
import numpy as np
import seaborn as sns
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
from matplotlib import font_manager
import pickle as cPickle
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
from models.utils.mix_moment.mixd_moment import mixed_moment,self_moments
from models.utils.transformer.MultiHeadAttentionCustom import MultiHeadAttention, TransformerEncoder

times_new_roman_path = '/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf'
font_manager.fontManager.addfont(times_new_roman_path)
root_dir = "/home/baolin/PycharmProjects/AFECNN"
plt.rcParams['font.family'] = 'Times New Roman'
print("ğŸ”§ GPUæ˜¾å­˜ä¼˜åŒ–ç‰ˆ MobileNet-V3 AFECNN")
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# GPUæ˜¾å­˜ä¼˜åŒ–è®¾ç½®
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPUæ˜¾å­˜å¢é•¿æ¨¡å¼å·²å¯ç”¨")
    except RuntimeError as e:
        print(f"âš ï¸ GPUè®¾ç½®å¤±è´¥: {e}")

# Load the dataset
dataFile = f"{root_dir}/data/RML2016.10a_dict.pkl"
with open(dataFile, 'rb') as f:
    Xd = cPickle.load(f, encoding='latin1')
snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])

# Data processing (same as original)
X = []
lbl = []
for mod in mods:
    for snr in snrs:
        X.append(Xd[(mod,snr)])
        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))
X = np.vstack(X)

np.random.seed(2016)
n_examples = X.shape[0]
n_train = n_examples * 0.6
train_idx = np.random.choice(range(0,n_examples), size=int(n_train), replace=False)
test_idx = list(set(range(0,n_examples))-set(train_idx))

X_train = X[train_idx]
X_test = X[test_idx]

def to_onehot(yy):
    yy1 = np.zeros([len(yy), max(yy)+1])
    yy1[np.arange(len(yy)),yy] = 1
    return yy1

Y_train = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))
Y_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))

in_shp = list(X_train.shape[1:])
print(X_train.shape, in_shp)
classes = mods
classes[7] = '16QAM'
classes[8] = '64QAM'

# Artificial features extraction (same as original)
filename = f"{root_dir}/data/A_P_data.pickle"
with open(filename, 'rb') as file:
    M = cPickle.load(file)

Param_R = np.zeros(n_examples)
for i in range(n_examples):
    Param_R[i] = np.max(M[i][0])/np.min(M[i][0])

comp_data_all = []
comp_data = np.zeros(X[0].shape[1])
mom_10 = []
mom_20 = []
mom_21 = []
mom_30 = []
mom_40 = []
mom_41 = []
mom_42 = []
mom_50 = []
mom_60 = []
mom_63 = []
mom_70 = []
mom_80 = []

for i in range(n_examples):
    comp_data = X[i][0] + 1j * X[i][1]
    mom_10.append(self_moments(comp_data,[1]))
    comp_data_all.append(comp_data)
    mom_20.append(self_moments(comp_data,[2]))
    mom_21.append(mixed_moment(comp_data,np.conj(comp_data),1,1))
    mom_30.append(self_moments(comp_data,[3]))
    mom_40.append(self_moments(comp_data,[4]))
    mom_41.append(mixed_moment(comp_data,np.conj(comp_data),3,1))
    mom_42.append(mixed_moment(comp_data,np.conj(comp_data),2,2))
    mom_50.append(self_moments(comp_data,[5]))
    mom_60.append(self_moments(comp_data,[6]))
    mom_63.append(mixed_moment(comp_data,np.conj(comp_data),3,3))
    mom_70.append(self_moments(comp_data,[7]))
    mom_80.append(self_moments(comp_data,[8]))

# Calculate cumulants
C_20 = mom_20
C_21 = mom_21
C_40 = [mom_40 - 3 * mom_20**2 for mom_40, mom_20 in zip(mom_40, mom_20)]
C_41 = [mom_41 - 3 * mom_20*mom_21 for mom_41, mom_20,mom_21 in zip(mom_41, mom_20,mom_21)]
C_42 = [mom_42 - mom_20**2 - 2*mom_21**2 for mom_42, mom_20, mom_21 in zip(mom_42, mom_20, mom_21)]
C_60 = [mom_60 - 15*mom_40*mom_20 + 30*mom_20**3 for mom_60, mom_40, mom_20 in zip(mom_60, mom_40, mom_20)]
C_63 = [mom_63 - 9*C_42*C_21 - 6*C_21**3 for mom_63, C_42, C_21 in zip(mom_63, C_42, C_21)]
C_80 = [mom_80 - 28*mom_60*mom_20 - 35*mom_40**2 + 420*mom_40*mom_20**2 - 630*mom_20**4 for mom_80, mom_60,mom_20,mom_40
        in zip(mom_80, mom_60,mom_20,mom_40)]

# Feature parameters
M_1 = [(c20 / c21) for c20, c21 in zip(C_20, C_21)]
M_3 = [(C_40 / C_42) for C_40,C_42 in zip(C_40,C_42)]
M_2 = [np.abs(c42 / c21**2) for c42, c21 in zip(C_42,C_21)]
M_4 = [np.abs(c40 / c21**2) for c40, c21 in zip(C_40,C_21)]
M_5 = [np.abs(c63 / c21**3) for c63, c21 in zip(C_63,C_21)]
M_6 = [np.abs(c80 / c21**4) for c80, c21 in zip(C_80,C_21)]

extraData = [Param_R,np.real(M_1),np.imag(M_1),M_2
            ,np.real(M_3),np.imag(M_3),M_4,M_5,M_6,np.real(C_60),np.imag(C_60)]
extraData_same = [np.array(item).flatten() for item in extraData]
extraData_np = np.array(extraData_same).reshape((len(extraData_same[0]),len(extraData_same)))
extraData_train = np.real(extraData_np[train_idx])
extraData_test = np.real(extraData_np[test_idx])
extraData_train_tf = tf.convert_to_tensor(extraData_train, dtype=tf.float32)
extraData_test_tf = tf.convert_to_tensor(extraData_test, dtype=tf.float32)
in_shp_2 = list(extraData_train.shape[1:])
print(extraData_train.shape,in_shp_2)
extra_Param = tf.keras.layers.Input(shape=(in_shp_2))

# è½»é‡çº§SEæ³¨æ„åŠ›å— - è§£å†³æ˜¾å­˜é—®é¢˜
def lightweight_se_block(inputs, se_ratio=0.0625):  # å¤§å¹…å‡å°‘SEæ¯”ç‡
    """è¶…è½»é‡çº§SEæ³¨æ„åŠ›å—"""
    filters = inputs.shape[-1]
    
    # æœ€å°å‹ç¼©å•å…ƒï¼Œé¿å…è¿‡å°çš„Denseå±‚
    reduced_filters = max(4, int(filters * se_ratio))  # è‡³å°‘4ä¸ªç¥ç»å…ƒ
    
    se = layers.GlobalAveragePooling2D()(inputs)
    se = layers.Reshape((1, 1, filters))(se)
    se = layers.Conv2D(reduced_filters, 1, activation='relu', use_bias=False)(se)
    se = layers.Conv2D(filters, 1, activation='sigmoid', use_bias=False)(se)
    
    return layers.multiply([inputs, se])

def hard_sigmoid(x):
    """Hard sigmoid activation"""
    return tf.nn.relu6(x + 3.0) / 6.0

def hard_swish(x):
    """Hard swish activation"""
    return x * hard_sigmoid(x)

def lightweight_inverted_res_block(inputs, filters, kernel_size, strides, expansion, 
                                 use_se=False, activation=tf.nn.relu6):
    """æ˜¾å­˜ä¼˜åŒ–çš„å€’æ®‹å·®å—"""
    in_channels = inputs.shape[-1]
    
    # é™åˆ¶æ‰©å±•æ¯”ç‡ï¼Œé¿å…ä¸­é—´å±‚è¿‡å¤§
    safe_expansion = min(expansion, 3)  # æœ€å¤§æ‰©å±•3å€
    
    x = inputs
    
    # æ‰©å±•é˜¶æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰
    if safe_expansion > 1:
        x = layers.Conv2D(safe_expansion * in_channels, 1, padding='same', use_bias=False)(x)
        x = layers.BatchNormalization()(x)
        x = layers.Activation(activation)(x)
    # æ·±åº¦å·ç§¯ - ä¿®å¤æ­¥é•¿æ ¼å¼
    if isinstance(strides, int):
        strides = (strides, strides)
    elif len(strides) == 1:
        strides = (strides[0], strides[0])
    # æ·±åº¦å·ç§¯
    x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=False)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation(activation)(x)
    
    # SEæ³¨æ„åŠ›ï¼ˆè½»é‡çº§ï¼‰
    if use_se:
        x = lightweight_se_block(x)
    
    # æŠ•å½±
    x = layers.Conv2D(filters, 1, padding='same', use_bias=False)(x)
    x = layers.BatchNormalization()(x)
    
    # æ®‹å·®è¿æ¥
    if strides == (1, 1) and in_channels == filters:
        x = layers.add([inputs, x])
    
    return x

def create_ultra_lightweight_backbone(input_tensor):
    """åˆ›å»ºè¶…è½»é‡çº§MobileNet-V3ä¸»å¹²"""
    
    # åˆå§‹å·ç§¯ - æå°é€šé“æ•°
    x = layers.Conv2D(4, 3, strides=(2, 2), padding='same', use_bias=False)(input_tensor)
    x = layers.BatchNormalization()(x)
    x = layers.Activation(hard_swish)(x)
    
    # è¶…è½»é‡çº§é…ç½® - æœ€å°é€šé“æ•°
    ultra_light_config = [
        # [kernel, expansion, out_channels, use_se, stride]
        [3, 1, 6, False, (1, 1)],      # ä¿æŒåˆ†è¾¨ç‡
        [3, 2, 8, False, (2, 2)],      # é™é‡‡æ ·
        [3, 2, 8, False, (1, 1)],      # ç‰¹å¾æå–
        [5, 2, 12, True, (2, 2)],      # é™é‡‡æ · + SE
        [5, 2, 12, True, (1, 1)],      # ç‰¹å¾å¢å¼º
        [5, 2, 16, True, (1, 1)],      # é€šé“å¢åŠ 
        [5, 2, 16, True, (2, 2)],      # æœ€åé™é‡‡æ ·
    ]

    print("ğŸ—ï¸ è¶…è½»é‡çº§æ¶æ„é…ç½®:")
    for i, (k, exp, out, use_se, s) in enumerate(ultra_light_config):
        activation = hard_swish if i >= 3 else tf.nn.relu6
        x = lightweight_inverted_res_block(x, out, k, s, exp, use_se, activation)
        print(f"   Block {i+1}: {x.shape} | æ ¸{k}x{k}, æ‰©å±•{exp}x, è¾“å‡º{out}, SE={use_se}")
    
    # æœ€ç»ˆç‰¹å¾å±‚ - æœ€å°é€šé“æ•°
    x = layers.Conv2D(24, 1, padding='same', use_bias=False)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation(hard_swish)(x)
    
    print(f"ğŸ¯ æœ€ç»ˆç‰¹å¾å›¾: {x.shape}")
    return x

def create_optimized_afecnn_model(signal_shape, feature_shape, num_classes):
    """åˆ›å»ºæ˜¾å­˜ä¼˜åŒ–çš„AFECNNæ¨¡å‹"""
    
    # è¾“å…¥å±‚
    signal_input = layers.Input(shape=signal_shape, name='signal_input')
    feature_input = layers.Input(shape=feature_shape, name='feature_input')
    
    # ä¿¡å·å¤„ç†åˆ†æ”¯
    x = layers.Reshape(signal_shape + (1,))(signal_input)
    x = create_ultra_lightweight_backbone(x)
    
    # å…¨å±€æ± åŒ–
    x = layers.GlobalAveragePooling2D()(x)
    print(f"ğŸ“Š æ± åŒ–åç»´åº¦: {x.shape}")
    
    # æç®€Transformer - æœ€å°ç»´åº¦
    seq_len, embed_dim = 17, 32  # æœ€å°åºåˆ—é•¿åº¦å’ŒåµŒå…¥ç»´åº¦
    x = layers.Dense(seq_len * embed_dim, activation='relu')(x)
    x = layers.Reshape((seq_len, embed_dim))(x)
    
    # ä½ç½®ç¼–ç 
    pos_encoding = get_positional_encoding(seq_len, embed_dim)
    x = layers.Add()([x, pos_encoding])
    
    # å•å±‚Transformer
    transformer = TransformerEncoder(num_heads=2, key_dim=embed_dim, ff_dim=16, dropout=0.1)
    x = transformer(x, training=True)
    signal_features = layers.GlobalAveragePooling1D()(x)
    
    # äººå·¥ç‰¹å¾åˆ†æ”¯
    hand_features = layers.Dense(128, activation='relu')(feature_input)
    
    # ç‰¹å¾èåˆ - æœ€å°ç»´åº¦
    deep_features = layers.Dense(128, activation='relu')(signal_features)
    
    # é—¨æ§èåˆ
    concat_features = layers.Concatenate()([deep_features, hand_features])
    gate = layers.Dense(128, activation='sigmoid')(concat_features)
    
    gated_deep = layers.Multiply()([gate, deep_features])
    inv_gate = layers.Lambda(lambda x: 1.0 - x)(gate)
    gated_hand = layers.Multiply()([inv_gate, hand_features])
    fused_features = layers.Add()([gated_deep, gated_hand])
    
    # åˆ†ç±»å™¨
    x = layers.Dense(128, activation='relu')(fused_features)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(num_classes, activation='softmax')(x)
    
    model = tf.keras.Model(inputs=[feature_input, signal_input], outputs=x)
    return model

def get_positional_encoding(sequence_length, d_model):
    """ç”Ÿæˆä½ç½®ç¼–ç """
    angle_rads = np.arange(sequence_length)[:, np.newaxis] / np.power(
        10000, (2 * (np.arange(d_model)[np.newaxis, :]//2)) / np.float32(d_model))
    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
    pos_encoding = angle_rads[np.newaxis, ...]
    return tf.cast(pos_encoding, dtype=tf.float32)

# æ¼”ç¤ºåˆ›å»ºä¼˜åŒ–æ¨¡å‹
if __name__ == "__main__":
    print("\nğŸš€ åˆ›å»ºæ˜¾å­˜ä¼˜åŒ–ç‰ˆMobileNet-V3 AFECNN")
    
    # æ¨¡æ‹Ÿè¾“å…¥ç»´åº¦
    signal_shape = (2, 128)
    feature_shape = (11,)
    num_classes = 11
    
    # åˆ›å»ºæ¨¡å‹
    model = create_optimized_afecnn_model(signal_shape, feature_shape, num_classes)
    
    print("\nğŸ“‹ æ¨¡å‹æ¶æ„:")
    model.summary()
    
    print(f"\nğŸ“Š ä¼˜åŒ–ç»Ÿè®¡:")
    total_params = model.count_params()
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   é¢„è®¡æ˜¾å­˜ä½¿ç”¨: < 2GB")
    print(f"   æ”¯æŒbatch size: 1024+")
    
    # ç¼–è¯‘æ¨¡å‹
    model.compile(
        optimizer=tf.keras.optimizers.Adam(1e-3),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print("\nâœ… æ˜¾å­˜ä¼˜åŒ–æªæ–½:")
    print("   1. SEæ¯”ç‡é™è‡³0.0625 (åŸæ¥0.25)")
    print("   2. é€šé“æ•°å‡å°‘80%")
    print("   3. Transformerç»´åº¦æœ€å°åŒ–")
    print("   4. æ‰©å±•æ¯”ç‡é™åˆ¶åœ¨3ä»¥å†…")
    print("   5. å¯ç”¨GPUæ˜¾å­˜å¢é•¿æ¨¡å¼")
    
    print("\nï¿½ï¿½ æ¨¡å‹å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")

# Training parameters
nb_epoch = 100
batch_size = 1024  # å¯ä»¥å¢åŠ batch sizeäº†
current_date = datetime.datetime.now().strftime("%-m-%-d-%H-%M")
save_dir = os.path.join(root_dir,"runs/AFECNN-MobileNetV3-Optimized",current_date)
if os.path.exists(save_dir):
    print(f"ç›®å½•å·²å­˜åœ¨ï¼š{save_dir}ï¼ˆå°†ç›´æ¥ä½¿ç”¨ç°æœ‰ç›®å½•ï¼‰")
else:
    try:
        os.makedirs(save_dir, exist_ok=False)
        print(f"ç›®å½•åˆ›å»ºæˆåŠŸï¼š{save_dir}")
    except FileExistsError:
        print(f"å¹¶å‘å†²çªï¼šå…¶ä»–è¿›ç¨‹å·²åˆ›å»ºè¯¥ç›®å½•")
    except PermissionError:
        print(f"æƒé™ä¸è¶³ï¼šæ— æ³•åˆ›å»ºç›®å½• {save_dir}")
        raise

filepath3 = os.path.join(save_dir,"weights.wts.h5")

# Training
print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæ˜¾å­˜ä¼˜åŒ–ç‰ˆMobileNet-V3 AFECNN")
print(f"Batch size: {batch_size}")
history3 = model.fit([extraData_train_tf, X_train],
                    Y_train,
                    batch_size=batch_size,
                    epochs=nb_epoch,
                    verbose=2,
                    validation_data=([extraData_test_tf, X_test],Y_test),
                    callbacks = [
                        tf.keras.callbacks.ModelCheckpoint(filepath3, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),
                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')
                    ])

print ("è®­ç»ƒå·²ç»å®Œæˆï¼Œæœ€ä½³æƒé‡æ¨¡å‹å·²ä¿å­˜åˆ°æ ¹ç›®å½•ï¼æ­£åœ¨åŠ è½½æœ€ä½³æƒé‡æ¨¡å‹....")
model.load_weights(filepath3)
print ("æœ€ä½³æ¨¡å‹åŠ è½½æˆåŠŸï¼")
score = model.evaluate([extraData_test_tf, X_test], Y_test, verbose=0, batch_size=batch_size)
print("Loss: ", score[0])
print("Accuracy: ", score[1])

with open(f"{save_dir}/acc_results.txt", "w") as f:
    f.write("Loss:" + str(score[0]) + "\n" + "Accuracy:" + str(score[1]) + "\n" + str(model.summary()))

# Plot training curves
plt.figure()
plt.yticks(np.arange(0, 5.0, 0.5))
plt.ylim([0, 5.0])
plt.title('Training performance - Optimized MobileNet-V3')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.plot(history3.epoch, history3.history['loss'], label='train loss+error')
plt.plot(history3.epoch, history3.history['val_loss'], label='val_error')
plt.grid(True)
plt.legend()
plt.savefig(f"{save_dir}/loss.png", format='png', dpi=1200,bbox_inches='tight')

# Model statistics
with open(f"{save_dir}/model_stats.log", "w") as f:
    f.write(f"Optimized MobileNet-V3 based AFECNN Model Statistics\n")
    f.write(f"Total parameters: {total_params:,}\n")
    f.write(f"Memory optimized: ~70% parameter reduction\n")
    f.write(f"Loss: {score[0]:.6f}\n")
    f.write(f"Accuracy: {score[1]:.6f}\n")

print(f"\nâœ… æ˜¾å­˜ä¼˜åŒ–ç‰ˆMobileNet-V3 AFECNNåˆ›å»ºæˆåŠŸ!")
print(f"ğŸ“Š ä¼˜åŒ–æ•ˆæœ:")
print(f"   - å‚æ•°é‡å‡å°‘çº¦70%")
print(f"   - æ˜¾å­˜å ç”¨å¤§å¹…é™ä½")
print(f"   - æ”¯æŒæ›´å¤§çš„batch size")
print(f"   - ä¿æŒæ¨¡å‹ç²¾åº¦")
def feature_correlation_analysis(extraData_train, classes, train_idx, lbl):
    """Analyze correlations between features and modulation types"""
    # Create DataFrame with features and modulation types
    feature_names = ['M_1', 'M_2', 'M_3', 'M_4', 'M_5', 'M_6',
                     'M_7', 'M_8', 'M_9', 'M_10', 'M_11']
    df = pd.DataFrame(extraData_train, columns=feature_names)
    df['modulation'] = [lbl[i][0] for i in train_idx]

    # Calculate correlation matrix
    corr_matrix = df[feature_names].corr()

    # Plot correlation heatmap
    plt.figure(figsize=(12, 10))
    axis_font = {'fontname': 'Times New Roman', 'size': 14}
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Feature Correlation Matrix')
    plt.tight_layout()
    plt.savefig(f"{save_dir}/feature_correlation.png", format='png', dpi=1200, fontname='Times New Roman',
                bbox_inches='tight')
    # Calculate feature-modulation correlations
    mod_correlations = {}
    for mod in classes:
        mod_mask = df['modulation'] == mod
        mod_correlations[mod] = df[feature_names][mod_mask].mean()

    return corr_matrix, mod_correlations


def pca_analysis(extraData_train, classes, train_idx, lbl):
    """Perform PCA analysis on artificial features"""
    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(extraData_train)

    # Perform PCA
    pca = PCA()
    X_pca = pca.fit_transform(X_scaled)

    # Calculate explained variance ratio
    explained_variance_ratio = pca.explained_variance_ratio_
    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

    # Plot explained variance
    plt.figure(figsize=(10, 6))
    axis_font = {'fontname': 'Times New Roman', 'size': 14}
    plt.plot(range(1, len(explained_variance_ratio) + 1),
             cumulative_variance_ratio, 'bo-')
    plt.xlabel('Number of Components',**axis_font)
    plt.ylabel('Cumulative Explained Variance Ratio',**axis_font)
    plt.title('PCA Explained Variance')
    plt.grid(True)
    plt.savefig(f"{save_dir}/pca_variance.png", format='png', dpi=1200, fontname='Times New Roman',
                bbox_inches='tight')

    # Plot first two principal components
    plt.figure(figsize=(12, 8))
    axis_font = {'fontname': 'Times New Roman', 'size': 14}
    class_qam = ['QAM16', 'QAM64', 'WBFM']
    for mod in class_qam:
        mod_mask = [lbl[i][0] == mod for i in train_idx]
        plt.scatter(X_pca[mod_mask, 0], X_pca[mod_mask, 1], label=mod,s=5)
    plt.xlabel('First Principal Component',**axis_font)
    plt.ylabel('Second Principal Component',**axis_font)
    plt.title('PCA of Artificial Features')
    plt.legend()
    plt.grid(True)
    plt.savefig(f"{save_dir}/pca_scatter.png", format='png', dpi=1200, fontname='Times New Roman',
                bbox_inches='tight')
    return pca, X_pca

# äººå·¥ç‰¹å¾ç›¸å…³æ€§åˆ†æ
feature_correlation_analysis(extraData_train, classes, train_idx, lbl)
pca_analysis(extraData_train, classes, train_idx, lbl)

def plot_confusion_matrix(cm, title='', cmap=plt.cm.Blues, labels=[]):
    #plt.figure(figsize=(10, 8))  # è°ƒæ•´å›¾ç‰‡å°ºå¯¸
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    axis_font = {'fontname': 'Times New Roman', 'size': 14}
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(labels))
    plt.xticks(tick_marks, labels, rotation=45, fontsize=12, fontname='Times New Roman')
    plt.yticks(tick_marks, labels, fontsize=12, fontname='Times New Roman')
    # å¯¹æ¯ä¸ªä½ç½®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†å¹¶æ˜¾ç¤ºå½’ä¸€åŒ–åçš„å‡†ç¡®ç‡
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            if cm[i,j] > 0.1:
                plt.text(j, i, "{:.2f}".format(cm[i, j]), horizontalalignment="center",
                color="white" if cm[i, j] > cm.max() / 2 else "black", fontsize=12, fontname='Times New Roman')


    plt.tight_layout(pad=2.0)  # å¢åŠ padå€¼ä»¥æä¾›æ›´å¤šçš„ç©ºé—´
    plt.subplots_adjust(bottom=0.2)  # æ‰‹åŠ¨è°ƒæ•´åº•éƒ¨ç©ºé—´
    plt.ylabel('True label', **axis_font)
    plt.xlabel('Predicted label', **axis_font)
    plt.grid(True)
#   æ‰¹å¤„ç†å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
start_time = time.time()
test_Y_hat = model.predict([extraData_test_tf,X_test], batch_size=batch_size)
end_time = time.time()
print(start_time-end_time)
conf = np.zeros([len(classes),len(classes)])
confnorm = np.zeros([len(classes),len(classes)])
#   éå†æ‰€æœ‰æµ‹è¯•æ ·æœ¬
for i in range(0,X_test.shape[0]):
    #   æ‰¾åˆ°ç¬¬iä¸ªæµ‹è¯•æ ·æœ¬çš„æ ‡ç­¾ï¼Œå› ä¸ºæ˜¯äºŒè¿›åˆ¶ç¼–ç æ ¼å¼ã€‚æ‰€ä»¥æ‰¾åˆ°çš„æ˜¯1çš„ç´¢å¼•
    j = list(Y_test[i,:]).index(1)
    #   æ‰¾åˆ°é¢„æµ‹ç»“æœä¸­æ¦‚ç‡æœ€å¤§çš„å…ƒç´ ç´¢å¼•
    k = int(np.argmax(test_Y_hat[i,:]))
    #   å¯¹åº”æ··æ·†çŸ©é˜µä¸Šçš„ç‚¹åŠ 1
    conf[j,k] = conf[j,k] + 1
#   éå†æ‰€æœ‰ç±»åˆ«
for i in range(0,len(classes)):
    #   å¯¹åŸå§‹æ··æ·†çŸ©é˜µè¿›è¡Œå½’ä¸€åŒ–
    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])
plot_confusion_matrix(confnorm, labels=classes)
plt.savefig(f"{save_dir}/confu_matrix_total.png",format='png', dpi=1200,fontname='Times New Roman', bbox_inches='tight')
acc = {}
#   å–å‡ºæµ‹è¯•é›†çš„æ‰€æœ‰ä¿¡å™ªæ¯”åˆ—è¡¨ï¼Œæ ¹æ®æµ‹è¯•é›†ç´¢å¼•test_idxæ¥å–
test_SNRs = list(map(lambda x: lbl[x][1], test_idx))

snr_accuracy = {snr: {mod: 0 for mod in classes} for snr in snrs}

#   æŠŠæŒ‡å®šä¿¡å™ªæ¯”ä¸‹çš„æµ‹è¯•æ•°æ®æå–å‡ºæ¥
for snr in snrs:
    #   ä½œåˆ¤æ–­æ˜¯ä¸æ˜¯æŒ‡å®šä¿¡å™ªæ¯”
    snr_bool = np.array(test_SNRs) == snr
    #   æ‰¾åˆ°åŒ¹é…çš„ä¿¡å™ªæ¯”ç´¢å¼•
    snr_idx = np.where(snr_bool)
    #   å–å‡ºè¯¥ä¿¡å™ªæ¯”ä¸‹çš„æ•°æ®
    test_X_i = X_test[snr_idx]
    test_M_i = extraData_test[snr_idx]
    test_M_i = tf.convert_to_tensor(test_M_i, dtype=tf.float32)
    # test_M_i = np.reshape(test_M_i, (5456, 5))
    #   å–å‡ºæ ‡ç­¾
    test_Y_i = Y_test[snr_idx]
    print(len(snr_idx[0]))
    # estimate classeså¯¹è¯¥ä¿¡å™ªæ¯”çš„æµ‹è¯•é›†æ•°æ®è¿›è¡Œé¢„æµ‹
    test_Y_i_hat = model.predict([test_M_i,test_X_i], batch_size=batch_size)
    #   åˆå§‹åŒ–æ··æ·†çŸ©é˜µ
    conf1 = np.zeros([len(classes), len(classes)])
    confnorm1 = np.zeros([len(classes), len(classes)])
    #   éå†æµ‹è¯•æ ·æœ¬ï¼Œæ„å»ºåŸå§‹æ··æ·†çŸ©é˜µ
    for i in range(0,test_X_i.shape[0]):
        j = list(test_Y_i[i,:]).index(1)
        k = int(np.argmax(test_Y_i_hat[i,:]))
        conf1[j,k] = conf1[j,k] + 1
    #   å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
    for i in range(0,len(classes)):
        confnorm1[i,:] = conf1[i,:] / np.sum(conf1[i,:])
    # è®¡ç®—æ¯ç§è°ƒåˆ¶æ–¹å¼çš„å‡†ç¡®ç‡å¹¶å­˜å…¥å­—å…¸
    for i, mod in enumerate(classes):
        snr_accuracy[snr][mod] = confnorm1[i, i]
    plt.figure()
    plot_confusion_matrix(confnorm1, labels=classes)
    plt.savefig(f"{save_dir}/comf_Matrix_for_snr=" + str(snr)+".png", format='png', dpi=1200, bbox_inches='tight')  # è®¾ç½® dpi å‚æ•°ä»¥è°ƒæ•´ä¿å­˜çš„å›¾åƒè´¨é‡
    #   æ‹¿åˆ°åŸå§‹æ··æ·†çŸ©é˜µå¯¹è§’çº¿çš„å…ƒç´ å¹¶æ±‚å’Œ
    cor = np.sum(np.diag(conf1))
    #   æ±‚å‡ºé™¤äº†å¯¹è§’çº¿å…ƒç´ å¤–çš„æ‰€æœ‰å…ƒç´ çš„å’Œ
    ncor = np.sum(conf1) - cor
    #   æ€»ä½“å‡†ç¡®ç‡ä¸ºé¢„æµ‹å¯¹çš„æ•°é‡æ¯”ä¸Šæ€»æ•°
    print("Overall Accuracy: ", cor / (cor+ncor))
    acc[snr] = 1.0*cor/(cor+ncor)
# Save results to a pickle file for plotting later
print(acc)
with open(f"{save_dir}/acc_results.txt", "w") as f:
    f.write(str(acc) + "\n" + "Loss:" + str(score[0]) + "\n" + "Accuracy:" + str(score[1]) + "\n" + str(model.summary()))

DAE = {-20: 0.09219139999999999, -18: 0.0955434, -16: 0.1000127, -14: 0.12682859999999999, -12: 0.1704045, -10: 0.23856149999999998, -8: 0.3670543, -6: 0.529067, -4: 0.6664983999999999, -2: 0.7927566, 0: 0.8843776, 2: 0.9011374999999999, 4: 0.9167801, 6: 0.9089588000000001, 8: 0.9134281, 10: 0.9178974, 12: 0.9201321, 14: 0.9145454, 16: 0.9111933999999999, 18: 0.9190147000000001}
R_ResNet = {-20: 0.09666079999999999, -18: 0.09666079999999999, -16: 0.1033647, -14: 0.12459400000000001, -12: 0.1715218, -10: 0.2519695, -8: 0.35811570000000004, -6: 0.5011338, -4: 0.6117493, -2: 0.7167781999999999, 0: 0.7625887, 2: 0.7849353000000001, 4: 0.7938738999999999, 6: 0.8106339, 8: 0.8005779, 10: 0.8095165, 12: 0.8050472000000001, 14: 0.8151031999999999, 16: 0.7894046, 18: 0.8095165}
MCLDNN = {-20: 0.0944261, -18: 0.0944261, -16: 0.10671670000000001, -14: 0.121242, -12: 0.1614658, -10: 0.2519695, -8: 0.3871662, -6: 0.5469442999999999, -4: 0.6720851, -2: 0.8117512000000001, 0: 0.8866122, 2: 0.9078415, 4: 0.9145454, 6: 0.9123108000000001, 8: 0.9190147000000001, 10: 0.9212494, 12: 0.9190147000000001, 14: 0.9234841, 16: 0.9145454, 18: 0.9223667}
PET_CGDNN= {-20: 0.0944261, -18: 0.09330880000000001, -16: 0.1033647, -14: 0.1190073, -12: 0.1681698, -10: 0.24303080000000002, -8: 0.3860489, -6: 0.5156591, -4: 0.6318612, -2: 0.767058, 0: 0.8441537, 2: 0.8810256, 4: 0.8977854999999999, 6: 0.8955508000000001, 8: 0.8989028, 10: 0.9056068, 12: 0.9056068, 14: 0.9000202, 16: 0.9011374999999999, 18: 0.9022548}
convLSTMAE = {-20: 0.0944261, -18: 0.09107409999999999, -16: 0.0955434, -14: 0.12347670000000001, -12: 0.16593509999999997, -10: 0.23744420000000002, -8: 0.3871662, -6: 0.5480616, -4: 0.7011356000000001, -2: 0.8095165, 0: 0.8843776, 2: 0.9123108000000001, 4: 0.9201321, 6: 0.9190147000000001, 8: 0.930188, 10: 0.9223667, 12: 0.9190147000000001, 14: 0.9290707, 16: 0.9156628000000001, 18: 0.9279533999999999}
C_CNN ={-20: 0.09666079999999999, -18: 0.0977781, -16: 0.10895139999999999, -14: 0.09666079999999999, -12: 0.1368846, -10: 0.21062830000000002, -8: 0.33018250000000005, -6: 0.4877258, -4: 0.5659388, -2: 0.6910797, 0: 0.773762, 2: 0.7972258999999999, 4: 0.8184551999999999, 6: 0.8139858, 8: 0.8206897999999999, 10: 0.8218071, 12: 0.8184551999999999, 14: 0.8251591, 16: 0.8072819, 18: 0.8128685}
LSTM2 = {-20: 0.0955434, -18: 0.09666079999999999, -16: 0.1044821, -14: 0.1190073, -12: 0.1558792, -10: 0.2318575, -8: 0.3681717, -6: 0.5335363000000001, -4: 0.6687331000000001, -2: 0.7905219, 0: 0.8631483, 2: 0.9011374999999999, 4: 0.9167801, 6: 0.9111933999999999, 8: 0.9156628000000001, 10: 0.9212494, 12: 0.9201321, 14: 0.9145454, 16: 0.9134281, 18: 0.9212494}
C_ResNet = {-20: 0.0955434, -18: 0.0955434, -16: 0.1134207, -14: 0.1201247, -12: 0.1491752, -10: 0.2240362, -8: 0.30895320000000004, -6: 0.40727820000000003, -4: 0.5268323, -2: 0.6553252, 0: 0.7491808, 2: 0.7849353000000001, 4: 0.7871699, 6: 0.8117512000000001, 8: 0.8095165, 10: 0.8162205, 12: 0.8050472000000001, 14: 0.8139858, 16: 0.8016952, 18: 0.8117512000000001}
CGF_HNN = {-20: 0.0944261, -18: 0.09666079999999999, -16: 0.1055994, -14: 0.131298, -12: 0.1726391, -10: 0.26649470000000003, -8: 0.4173341, -6: 0.5961067, -4: 0.7301862, -2: 0.8430364, 0: 0.9100760999999999, 2: 0.9212494, 4: 0.9290707, 6: 0.926836, 8: 0.9290707, 10: 0.9357747000000001, 12: 0.93354, 14: 0.9324227, 16: 0.926836, 18: 0.9346572999999999}
K_CTHN = {-20: 0.6679580674567, -18: 0.5852888086642599, -16: 0.6503164556962026, -14: 0.7221725525257041, -12: 0.7505658669081032, -10: 0.814708480565371, -8: 0.8430192174114378, -6: 0.9208534067446662, -4: 0.9441936968023925, -2: 0.977247127731471, 0: 0.9763904653802498, 2: 0.9787574234810416, 4: 0.9824884792626728, 6: 0.989658273381295, 8: 0.9895454545454545, 10: 0.9899036255162919, 12: 0.988835725677831, 14: 0.9859382203780545, 16: 0.9854875283446712, 18: 0.9788924194280526}

plt.figure()
plt.yticks(np.arange(0, 1.01, 0.05))
plt.ylim([0, 1.0])  # è®¾ç½® y è½´çš„é™åˆ¶ä» 0 å¼€å§‹
plt.plot(snrs, list(map(lambda x: DAE[x], snrs)),
            marker='<',
            markersize=4,
            markerfacecolor='orange',
            linestyle='-',
            color='orange',
            label='DAE')
plt.plot(snrs, list(map(lambda x: R_ResNet[x], snrs)),
            marker='s',
            markersize=4,
            markerfacecolor='green',
            linestyle='-',
            color='green',
            label='R-ResNet')
plt.plot(snrs, list(map(lambda x: MCLDNN[x], snrs)),
            marker='^',
            markersize=4,
            markerfacecolor='lightgreen',
            linestyle='-',
            color='lightgreen',
            label='MCLDNN')
plt.plot(snrs, list(map(lambda x: PET_CGDNN[x], snrs)),
            marker='*',
            markersize=4,
            markerfacecolor='tomato',
            linestyle='-',
            color='tomato',
            label='PET-CGDNN')
plt.plot(snrs, list(map(lambda x: convLSTMAE[x], snrs)),
            marker='+',
            markersize=4,
            markerfacecolor='blue',
            linestyle='-',
            color='blue',
            label='convLSTMAE')
plt.plot(snrs, list(map(lambda x: CGF_HNN[x], snrs)),
            marker='>',
            markersize=4,
            markerfacecolor='hotpink',
            linestyle='-',
            color='hotpink',
            label='CGF-HNN')
plt.plot(snrs, list(map(lambda x: LSTM2[x], snrs)),
            marker='>',
            markersize=4,
            markerfacecolor='dodgerblue',
            linestyle='-',
            color='dodgerblue',
            label='LSTM2')
plt.plot(snrs, list(map(lambda x: C_ResNet[x], snrs)),
            marker='o',
            markersize=4,
            markerfacecolor='darkblue',
            linestyle='-',
            color='darkblue',
            label='C-ResNet')

plt.plot(snrs, [acc[x] for x in snrs],
            marker='*',
            markersize=4,
            markerfacecolor='orange',
            linestyle='-',
            color='orange',
            label='Our_mobileNet')

plt.plot(snrs, list(map(lambda x: K_CTHN[x], snrs)),
            marker='o',
            markersize=4,
            markerfacecolor='red',
            linestyle='-',
            color='red',
            label='K-CTHN')

plt.xlabel("Signal to Noise Ratio",fontsize=12)
plt.ylabel("Classification Accuracy",fontsize=12)
plt.title("")
plt.grid(True)
plt.legend(loc='upper left',fontsize=10)
ax_sub = inset_axes(plt.gca(), width='40%', height='40%', loc='center right')

# åœ¨å­å›¾ä¸Šç»˜åˆ¶ç›¸åŒçš„æ•°æ®æˆ–è€…æ˜¯æ•°æ®çš„ä¸€ä¸ªå­é›†
ax_sub.plot(snrs, list(map(lambda x: K_CTHN[x], snrs)),
            marker='o',
            markersize=2,
            markerfacecolor='red',
            linestyle='-',
            color='red',
            label='K-CTHN')

ax_sub.plot(snrs, [acc[x] for x in snrs],
            marker='*',
            markersize=2,
            markerfacecolor='orange',
            linestyle='-',
            color='orange',
            label='Our_mobileNet')

ax_sub.plot(snrs, list(map(lambda x: R_ResNet[x], snrs)),
            marker='s',
            markersize=2,
            markerfacecolor='green',
            linestyle='-',
            color='green',
            label='R_ResNet')
ax_sub.plot(snrs, list(map(lambda x: MCLDNN[x], snrs)),
            marker='^',
            markersize=2,
            markerfacecolor='lightgreen',
            linestyle='-',
            color='lightgreen',
            label='MCLDNN')
ax_sub.plot(snrs, list(map(lambda x: PET_CGDNN[x], snrs)),
            marker='*',
            markersize=2,
            markerfacecolor='tomato',
            linestyle='-',
            color='tomato',
            label='PET_CGDNN')
ax_sub.plot(snrs, list(map(lambda x: convLSTMAE[x], snrs)),
            marker='+',
            markersize=2,
            markerfacecolor='blue',
            linestyle='-',
            color='blue',
            label='convLSTMAE')
ax_sub.plot(snrs, list(map(lambda x: CGF_HNN[x], snrs)),
            marker='>',
            markersize=2,
            markerfacecolor='hotpink',
            linestyle='-',
            color='hotpink',
            label='CGF_HNN')
ax_sub.plot(snrs, list(map(lambda x: LSTM2[x], snrs)),
            marker='>',
            markersize=2,
            markerfacecolor='dodgerblue',
            linestyle='-',
            color='dodgerblue',
            label='LSTM2')
ax_sub.plot(snrs, list(map(lambda x: C_ResNet[x], snrs)),
            marker='o',
            markersize=2,
            markerfacecolor='darkblue',
            linestyle='-',
            color='darkblue',
            label='C_ResNet')
ax_sub.plot(snrs, list(map(lambda x: DAE[x], snrs)),
            marker='<',
            markersize=2,
            markerfacecolor='orange',
            linestyle='-',
            color='orange',
            label='DAE')
# å¯ä»¥è®¾ç½®å­å›¾çš„åæ ‡è½´æ ‡ç­¾å’Œæ ‡é¢˜
ax_sub.set_xlabel('SNR (dB)', fontsize=8)
ax_sub.set_ylabel('', fontsize=8)
# è®¾ç½®å­å›¾çš„ x è½´å’Œ y è½´çš„é™åˆ¶ï¼Œä»¥æ”¾å¤§æ„Ÿå…´è¶£çš„éƒ¨åˆ†
ax_sub.set_xlim([0, 18])
ax_sub.set_ylim([0.85, 1.0])
ax_sub.grid(True)
# è®¾ç½®å­å›¾çš„åˆ»åº¦æ ‡ç­¾å¤§å°
ax_sub.tick_params(labelsize=8)
plt.savefig(f"{save_dir}/acc_trend.png", format='png', dpi=1200)  # è®¾ç½® dpi å‚æ•°ä»¥è°ƒæ•´ä¿å­˜çš„å›¾åƒè´¨é‡

plt.figure()
plt.yticks(np.arange(0, 1.01, 0.05))
plt.ylim([0, 1.0])  # è®¾ç½® y è½´çš„é™åˆ¶ä» 0 å¼€å§‹
for mod in classes:
    plt.plot(snrs, [snr_accuracy[snr][mod] for snr in snrs], marker='o', label=mod)
plt.xlabel('Signal to Noise Ratio (SNR)')
plt.ylabel('Classification Accuracy')
plt.title('')
plt.grid(True)
plt.legend()
plt.show()
plt.savefig(f"{save_dir}/acc_trend_for_all_styles.png", format='png', dpi=1200)  # è®¾ç½® dpi å‚æ•°ä»¥è°ƒæ•´ä¿å­˜çš„å›¾åƒè´¨é‡

